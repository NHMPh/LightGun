 private PointF DetectEdge(Image<Bgr, byte> image)
        {
            // Convert to grayscale
            Image<Gray, Byte> gray = image.Convert<Gray, Byte>();

            // Increase contrast
             //  gray._EqualizeHist();

          //  Mat smoothed = new Mat();
           // CvInvoke.BilateralFilter(gray, smoothed, 9, 75, 75);
            // Apply Gaussian Blur to reduce noise
            // Image<Gray, Byte> blurred = gray.SmoothGaussian(5);
           // CvInvoke.GaussianBlur(gray, gray, new System.Drawing.Size(5, 5), 1.5);
            // Apply threshold to isolate white areas
            Mat thresholded = new Mat(); CvInvoke.Threshold(gray, thresholded, threadhold, 255, ThresholdType.Binary);

            // Apply morphological operations to enhance edges
           // Mat morph = new Mat(); Mat kernel = CvInvoke.GetStructuringElement(ElementShape.Rectangle, new Size(3, 3), new Point(-1, -1));
          //  CvInvoke.MorphologyEx(thresholded, morph, MorphOp.Dilate, kernel, new Point(-1, -1), 1, BorderType.Default, new MCvScalar());
           // CvInvoke.MorphologyEx(morph, morph, MorphOp.Erode, kernel, new Point(-1, -1), 1, BorderType.Default, new MCvScalar());

            // Detect edges using Canny
            //   Image<Gray, Byte> edged = new Image<Gray, byte>(gray.Size); 
            pictureBox1.Image = thresholded.ToBitmap();

            // CvInvoke.Canny(morph, edged, 100, 200); 
            // Adjust these values
            VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint();
            Mat hierarchy = new Mat();
            CvInvoke.FindContours(thresholded, contours, hierarchy, RetrType.Tree, ChainApproxMethod.ChainApproxSimple);

            List<VectorOfPoint> contourList = new List<VectorOfPoint>();
            for (int i = 0; i < contours.Size; i++)
            {
                if (contours[i].Size >= 4)
                {
                    contourList.Add(contours[i]);
                }

            }

            // Sort contours by area and take the top 10
            contourList.Sort((c1, c2) => CvInvoke.ContourArea(c2).CompareTo(CvInvoke.ContourArea(c1)));
            // contourList = contourList.GetRange(0, Math.Min(1, contourList.Count));
            VectorOfPoint biggest = BiggestContour(contourList);
            PointF topLeft = PointF.Empty;
            PointF topRight = PointF.Empty;
            PointF bottomRight = PointF.Empty;
            PointF bottomLeft = PointF.Empty;

            // topLeft = corners[0]; PointF topRight = corners[1]; PointF bottomRight = corners[2]; PointF bottomLeft = corners[3];
            // Assuming 'biggest' is a VectorOfPoint representing the biggest contour
            if (biggest.Size == 4)
            {
                // Convert VectorOfPoint to PointF array
                Point[] points = biggest.ToArray();
                PointF[] corners = Array.ConvertAll(points, p => new PointF(p.X, p.Y));

                // Calculate the center of the contour
                float centerX = 0, centerY = 0;
                foreach (var corner in corners)
                {
                    centerX += corner.X;
                    centerY += corner.Y;
                }
                centerX /= corners.Length;
                centerY /= corners.Length;

                // Assign corners based on their position relative to the center
                foreach (var corner in corners)
                {
                    if (corner.X < centerX && corner.Y < centerY) topLeft = corner;
                    else if (corner.X > centerX && corner.Y < centerY) topRight = corner;
                    else if (corner.X > centerX && corner.Y > centerY) bottomRight = corner;
                    else if (corner.X < centerX && corner.Y > centerY) bottomLeft = corner;
                }
                image.Draw(new CircleF(topLeft, 20), new Bgr(0, 0, 255), 10);
                image.Draw(new CircleF(topRight, 20), new Bgr(0, 255, 0), 10);
                image.Draw(new CircleF(bottomRight, 20), new Bgr(255, 0, 0), 10);
                image.Draw(new CircleF(bottomLeft, 20), new Bgr(0, 255, 255), 10);
                image.Draw(new CircleF(new PointF(image.Width / 2, image.Height / 2), 10), new Bgr(255, 255, 0), 5);
                pictureBox2.Image = image.ToBitmap();
                PointF pointToTrack = new PointF(ixres / 2, iyres / 2);
                Mat pointMat = new Mat(1, 1, DepthType.Cv32F, 2);
                pointMat.SetTo(new float[] { pointToTrack.X, pointToTrack.Y });
                // Assuming topLeft, topRight, bottomRight, and bottomLeft are defined and represent your source points
                PointF[] pts1 = new PointF[] {
                            topLeft,    // corners[0]
                            topRight,   // corners[1]
                            bottomRight,// corners[2]
                            bottomLeft  // corners[3]
                    };
                // Assuming you have another set of points representing the destination points
                PointF destTopLeft = new PointF(0, 0);
                PointF destTopRight = new PointF(ixres, 0);
                PointF destBottomRight = new PointF(ixres, iyres);
                PointF destBottomLeft = new PointF(0, iyres);
                PointF[] pts2 = new PointF[] {
                            destTopLeft,    // Destination for topLeft
                            destTopRight,   // Destination for topRight
                            destBottomRight,// Destination for bottomRight
                            destBottomLeft  // Destination for bottomLeft
                    };


                // Convert PointF arrays to Mat
                using (Mat srcPoints = new Mat(4, 1, DepthType.Cv32F, 2))
                using (Mat dstPoints = new Mat(4, 1, DepthType.Cv32F, 2))
                {
                    for (int i = 0; i < 4; i++)
                    {
                        srcPoints.SetTo(pts1);
                        dstPoints.SetTo(pts2);
                    }
                    // Get the perspective transformation matrix
                    Mat matrix = CvInvoke.GetPerspectiveTransform(srcPoints, dstPoints);
                    // Apply the perspective transformation
                    Mat transformedPointMat = new Mat();
                    CvInvoke.PerspectiveTransform(pointMat, transformedPointMat, matrix);
                    // Convert the transformed Mat back to PointF
                    float[] transformedPointValues = new float[2];
                    Marshal.Copy(transformedPointMat.DataPointer, transformedPointValues, 0, 2);
                    PointF transformedPoint = new PointF((transformedPointValues[0] / ixres) * xres, (transformedPointValues[1] / iyres) * yres);
                    return transformedPoint;

                    // 'transformedFrame' now contains the transformed image
                }

            }
            else
            {
                pictureBox2.Image = image.ToBitmap();
            }
            return PointF.Empty;




        }
        using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.Util;
using Emgu.CV;
using Emgu.CV.Aruco;
using System.Runtime.InteropServices;
using Emgu.CV.Cuda;
using System.Drawing;
using System.Diagnostics;
using Emgu.CV.Dai;
using static System.Windows.Forms.VisualStyles.VisualStyleElement.Window;
namespace LightGun
{
    public partial class Form1 : Form
    {

        // Import the necessary Windows API functions

        int xres = 1920;
        int yres = 1080;



        static int ixres = 600;
        static int iyres = 480;
        bool detected = false;

        [DllImport("user32.dll")]
        static extern void mouse_event(int dwFlags, int dx, int dy, int dwData, int dwExtraInfo);
        static bool movable = false;
        // Mouse event constants
        private const int MOUSEEVENTF_LEFTDOWN = 0x02;
        private const int MOUSEEVENTF_LEFTUP = 0x04;
        bool streamVideo = false;
        Mat frame = new Mat();
        Size frameSize = new Size(ixres, iyres);
        Image<Bgr, byte> image;
        [DllImport("user32.dll")]
        private static extern bool SetCursorPos(int x, int y);
        static int cameraIndex = 1;
        static VideoCapture capture = new VideoCapture(cameraIndex);
        // Import necessary functions from user32.dll


        int threadhold = 200;
        float xOffset = 0;
        float yOffset = 0;

        double brightness = capture.Get(CapProp.Brightness);
        public Form1()
        {
            InitializeComponent();
            // Set the capture resolution
            capture.Set(CapProp.FrameWidth, ixres);
            capture.Set(CapProp.FrameHeight, iyres);
            // capture.Set(CapProp.AutoExposure, 0); // 0 means manual exposure
            capture.Set(CapProp.Fps, 30);
            this.KeyDown += MyForm_KeyDown;
            KeyPreview = true;
            pictureBox1.SizeMode = PictureBoxSizeMode.StretchImage;
            pictureBox2.SizeMode = PictureBoxSizeMode.StretchImage;
            // Set properties to control low-light behavior
            // Note: The values here are examples and may need to be adjusted
        }

        private void MyForm_KeyDown(object sender, KeyEventArgs e)
        {
            // Check if a specific key is pressed
            if (e.KeyCode == Keys.C)
            {
                movable = !movable;

            }
            // Check if a specific key is pressed
            if (e.KeyCode == Keys.A)
            {
                xres = 600;
                yres = 480;

            }
            if (e.KeyCode == Keys.S)
            {
                xres = 1920;
                yres = 1080;

            }
        }
        [DllImport("user32.dll")]
        public static extern bool GetCursorPos(out Point lpPoint);
        public static void MoveMouseToPointAsync(PointF targetPoint, int steps = 16, int duration = 35)
        {
            if (targetPoint == PointF.Empty) return;
            int x = (int)targetPoint.X;
            int y = (int)targetPoint.Y;
            if (movable)
                SetCursorPos(x, y);
        }
        public static Image<Bgr, byte> CropImageByRedDots(Image<Bgr, byte> image)
        {
            // Load the image


            // Convert to HSV
            Image<Hsv, byte> hsvImage = image.Convert<Hsv, byte>();

            // Define the lower and upper bounds for the red color in the first range
            Hsv lowerRed1 = new Hsv(0, 70, 50); // Adjust these values as needed
            Hsv upperRed1 = new Hsv(10, 255, 255); // Adjust these values as needed

            // Define the lower and upper bounds for the red color in the second range
            Hsv lowerRed2 = new Hsv(170, 70, 50); // Adjust these values as needed
            Hsv upperRed2 = new Hsv(180, 255, 255); // Adjust these values as needed

            // Create masks for both red ranges and combine them
            Image<Gray, byte> redMask1 = hsvImage.InRange(lowerRed1, upperRed1);
            Image<Gray, byte> redMask2 = hsvImage.InRange(lowerRed2, upperRed2);
            Image<Gray, byte> redMask = redMask1.Or(redMask2);

            // Optional: Apply some morphological operations to clean up the mask
            // e.g., CvInvoke.MorphologyEx(redMask, redMask, MorphOp.Close, null, new Point(-1, -1), 1, BorderType.Reflect, new MCvScalar());

            // Invert the mask if you want to highlight red areas instead of masking them
            // var mask = redMask.Not();

            // Set non-red areas to black (if that's the intention)

            // Find contours in the red mask
            VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint();
            Mat hierarchy = new Mat();
            CvInvoke.FindContours(redMask, contours, hierarchy, RetrType.External, ChainApproxMethod.ChainApproxSimple);

            // Create a new mask to draw the filtered contours
            Image<Gray, byte> filteredRedMask = new Image<Gray, byte>(redMask.Width, redMask.Height, new Gray(0));

            // Minimum area threshold for red areas
            double minArea = 4000; // Adjust this value as needed
            double maxArea = 30000;
            for (int i = 0; i < contours.Size; i++)
            {
                // Calculate the area of each contour
                double area = CvInvoke.ContourArea(contours[i]);

                // If the area is above the threshold, draw the contour on the new mask
                if (area > minArea && area < maxArea)
                {
                    CvInvoke.DrawContours(filteredRedMask, contours, i, new MCvScalar(255), -1); // -1 fills the contour
                }
            }

            // Now, use the filteredRedMask instead of redMask for further processing
            // If you want to set non-red areas to black (and have only the significant red areas), use the filtered mask
            image.SetValue(new Bgr(0, 0, 0), filteredRedMask.Not());
            // Find contours again, this time possibly for the filtered red dots
            VectorOfVectorOfPoint dotContours = new VectorOfVectorOfPoint();
            CvInvoke.FindContours(filteredRedMask, dotContours, null, RetrType.List, ChainApproxMethod.ChainApproxSimple);

            List<Point> centroids = new List<Point>();
            for (int i = 0; i < dotContours.Size; i++)
            {
                Moments moments = CvInvoke.Moments(dotContours[i]);
                int x = (int)(moments.M10 / moments.M00);
                int y = (int)(moments.M01 / moments.M00);
                centroids.Add(new Point(x, y));
            }

            // Sort centroids if necessary, depending on the shape you expect to form
            // This step is context-dependent and might require custom logic

            // Draw and fill the polygon formed by the centroids
            if (centroids.Count >= 3) // Need at least 3 points to form a polygon
            {
                // Sort the centroids if necessary. The sorting logic depends on the expected shape.
                // For a general quadrilateral, you might sort by X, then Y, but this is an oversimplification.
                // Custom sorting logic might be required for specific shapes or orientations.

                // Example of a simple sort that might not work for all quadrilaterals:
                centroids = centroids.OrderBy(p => p.X).ThenBy(p => p.Y).ToList();

                // Create a vector of points from the sorted centroids
                VectorOfPoint quadrilateralPoints = new VectorOfPoint(centroids.ToArray());

                // Draw and fill the quadrilateral
                // Note: FillConvexPoly works if the quadrilateral is convex. For non-convex shapes, this approach might not be suitable.
                CvInvoke.FillConvexPoly(image, quadrilateralPoints, new MCvScalar(255, 0, 0)); // Fill with red for visibility
            }

            return image;
            return image;
        }

        private void button1_Click(object sender, EventArgs e)
        {

            streamVideo = !streamVideo;
            cameraIndex = 1;
            capture = new VideoCapture(cameraIndex);
            Task.Run(async () => await StreamVideo());
        }

        private async Task StreamVideo()
        {

            while (streamVideo)
            {
                try
                {
                    capture.Read(frame);
                    CvInvoke.Resize(frame, frame, frameSize);
                    image = frame.ToImage<Bgr, byte>();
                    MoveMouseToPointAsync(DetectEdge(image));
                    await Task.Delay(16);
                }
                catch
                {

                }


            }
        }
        VectorOfPoint BiggestContour(List<VectorOfPoint> contours)
        {
            VectorOfPoint biggest = new VectorOfPoint();
            double maxArea = 0;
            foreach (var contour in contours)
            {
                double area = CvInvoke.ContourArea(contour);
                if (area > 1000)
                {
                    VectorOfPoint approx = new VectorOfPoint();
                    CvInvoke.ApproxPolyDP(contour, approx, 0.015 * CvInvoke.ArcLength(contour, true), true);



                    if (area > maxArea && approx.Size == 4)
                    {
                        biggest = approx;
                        maxArea = area;
                    }
                }
            }
            return biggest;
        }

        private PointF DetectEdge(Image<Bgr, byte> image)
        {
            // Convert to grayscale
            Image<Gray, Byte> gray = image.Convert<Gray, Byte>();
            CvInvoke.CLAHE(gray, 2, new Size(8, 8), gray);
            // Apply histogram equalization
            // Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)

            // Apply Gaussian blur to reduce noise and smooth out lighting variations
            CvInvoke.GaussianBlur(gray, gray, new Size(5, 5), 0);
            //  CvInvoke.EqualizeHist(gray, gray);
            Mat thresholded = new Mat(); CvInvoke.Threshold(gray, thresholded, threadhold, 255, ThresholdType.Binary);
            //  pictureBox1.Image = thresholded.ToBitmap();
            pictureBox1.Image = thresholded.ToBitmap();
            VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint();
            Mat hierarchy = new Mat();
            CvInvoke.FindContours(thresholded, contours, hierarchy, RetrType.Tree, ChainApproxMethod.ChainApproxSimple);
            // Process contours as needed
            /* foreach (var contour in contours.ToArrayOfArray())
             {
                 // Example: Draw contours on the original image
                 CvInvoke.DrawContours(image, contours, -1, new MCvScalar(0, 255, 0), 2);
             }*/

            List<VectorOfPoint> contourList = new List<VectorOfPoint>();
            for (int i = 0; i < contours.Size; i++)
            {
                if (contours[i].Size >= 4)
                {
                    contourList.Add(contours[i]);
                }

            }

            // Sort contours by area and take the top 10
            contourList.Sort((c1, c2) => CvInvoke.ContourArea(c2).CompareTo(CvInvoke.ContourArea(c1)));
            // contourList = contourList.GetRange(0, Math.Min(1, contourList.Count));
            VectorOfPoint biggest = BiggestContour(contourList);
            PointF topLeft = PointF.Empty;
            PointF topRight = PointF.Empty;
            PointF bottomRight = PointF.Empty;
            PointF bottomLeft = PointF.Empty;

            // topLeft = corners[0]; PointF topRight = corners[1]; PointF bottomRight = corners[2]; PointF bottomLeft = corners[3];
            // Assuming 'biggest' is a VectorOfPoint representing the biggest contour
            if (biggest.Size == 4)
            {
                // Convert VectorOfPoint to PointF array
                Point[] points = biggest.ToArray();
                PointF[] corners = Array.ConvertAll(points, p => new PointF(p.X, p.Y));

                // Calculate the center of the contour
                float centerX = 0, centerY = 0;
                foreach (var corner in corners)
                {
                    centerX += corner.X;
                    centerY += corner.Y;
                }
                centerX /= corners.Length;
                centerY /= corners.Length;

                // Assign corners based on their position relative to the center
                foreach (var corner in corners)
                {
                    if (corner.X < centerX && corner.Y < centerY) topLeft = corner;
                    else if (corner.X > centerX && corner.Y < centerY) topRight = corner;
                    else if (corner.X > centerX && corner.Y > centerY) bottomRight = corner;
                    else if (corner.X < centerX && corner.Y > centerY) bottomLeft = corner;
                }
                image.Draw(new CircleF(topLeft, 20), new Bgr(0, 0, 255), 10);
                image.Draw(new CircleF(topRight, 20), new Bgr(0, 255, 0), 10);
                image.Draw(new CircleF(bottomRight, 20), new Bgr(255, 0, 0), 10);
                image.Draw(new CircleF(bottomLeft, 20), new Bgr(0, 255, 255), 10);
                image.Draw(new CircleF(new PointF(image.Width / 2, image.Height / 2), 10), new Bgr(255, 255, 0), 5);
                pictureBox2.Image = image.ToBitmap();
                PointF pointToTrack = new PointF(ixres / 2 + xOffset, iyres / 2 + yOffset);
                Mat pointMat = new Mat(1, 1, DepthType.Cv32F, 2);
                pointMat.SetTo(new float[] { pointToTrack.X, pointToTrack.Y });
                // Assuming topLeft, topRight, bottomRight, and bottomLeft are defined and represent your source points
                PointF[] pts1 = new PointF[] {
                            topLeft,    // corners[0]
                            topRight,   // corners[1]
                            bottomRight,// corners[2]
                            bottomLeft  // corners[3]
                    };
                // Assuming you have another set of points representing the destination points
                PointF destTopLeft = new PointF(0, 0);
                PointF destTopRight = new PointF(ixres, 0);
                PointF destBottomRight = new PointF(ixres, iyres);
                PointF destBottomLeft = new PointF(0, iyres);
                PointF[] pts2 = new PointF[] {
                            destTopLeft,    // Destination for topLeft
                            destTopRight,   // Destination for topRight
                            destBottomRight,// Destination for bottomRight
                            destBottomLeft  // Destination for bottomLeft
                    };


                // Convert PointF arrays to Mat
                using (Mat srcPoints = new Mat(4, 1, DepthType.Cv32F, 2))
                using (Mat dstPoints = new Mat(4, 1, DepthType.Cv32F, 2))
                {
                    for (int i = 0; i < 4; i++)
                    {
                        srcPoints.SetTo(pts1);
                        dstPoints.SetTo(pts2);
                    }
                    // Get the perspective transformation matrix
                    Mat matrix = CvInvoke.GetPerspectiveTransform(srcPoints, dstPoints);
                    // Apply the perspective transformation
                    Mat transformedPointMat = new Mat();
                    CvInvoke.PerspectiveTransform(pointMat, transformedPointMat, matrix);
                    // Convert the transformed Mat back to PointF
                    float[] transformedPointValues = new float[2];
                    Marshal.Copy(transformedPointMat.DataPointer, transformedPointValues, 0, 2);
                    PointF transformedPoint = new PointF((transformedPointValues[0] / ixres) * xres, (transformedPointValues[1] / iyres) * yres);
                    detected = true;
                    return transformedPoint;

                    // 'transformedFrame' now contains the transformed image
                }

            }
            else
            {
                pictureBox2.Image = image.ToBitmap();

            }
            return PointF.Empty;




        }

     
    }
}
////////////////
using Emgu.CV.Structure;
using Emgu.CV;
using Emgu.CV.Dnn;
using Emgu.CV.Util;
using Emgu.CV.CvEnum;
using Emgu.CV.Features2D;
using Emgu.CV.XObjdetect;
using static System.Windows.Forms.VisualStyles.VisualStyleElement.Window;

namespace LightGun
{
    internal static class Program
    {

       
        /// <summary>
        ///  The main entry point for the application.
        /// </summary>
        [STAThread]
        static void Main()
        {
            

            // To customize application configuration such as set high DPI settings or default font,
            // see https://aka.ms/applicationconfiguration.
            ApplicationConfiguration.Initialize();
            Application.Run(new Form1());
            
          

        }
        private static void Test2()
        {
            // Load the image where you want to find the television
            Image<Bgr, byte> sceneImage = null;
            OpenFileDialog dialog = new OpenFileDialog();
            if (dialog.ShowDialog() == DialogResult.OK)
            {
                 sceneImage = new Image<Bgr, byte>(dialog.FileName).Resize(640, 480, Inter.Cubic);
            }
          

            // Load an image of the television for reference
            Mat televisionImage = CvInvoke.Imread("D:\\Project\\5.jpg", ImreadModes.Color);

            // Initialize the ORB detector
            int nFeatures = 500;
            ORB orbDetector = new ORB(nFeatures);

            // Detect keypoints and compute descriptors for both images
            VectorOfKeyPoint keypointsScene, keypointsTelevision;
            Mat descriptorsScene = new Mat(), descriptorsTelevision = new Mat();
            keypointsScene = new VectorOfKeyPoint();
            keypointsTelevision = new VectorOfKeyPoint();
            orbDetector.DetectAndCompute(sceneImage, null, keypointsScene, descriptorsScene, false);
            orbDetector.DetectAndCompute(televisionImage, null, keypointsTelevision, descriptorsTelevision, false);

            // Match descriptors using BFMatcher
            BFMatcher matcher = new BFMatcher(DistanceType.Hamming);
            VectorOfVectorOfDMatch matches = new VectorOfVectorOfDMatch();
            matcher.KnnMatch(descriptorsTelevision, descriptorsScene, matches, 2);

            // Filter matches using the Lowe's ratio test
            var goodMatches = new VectorOfDMatch();
            for (int i = 0; i < matches.Size; i++)
            {
                if (matches[i][0].Distance < 0.95 * matches[i][1].Distance)
                {
                    goodMatches.Push(new[] { matches[i][0] });
                }
            }

            // Find homography and corners of the television in the scene
            if (goodMatches.Size >= 4) // Need at least 4 matches
            {
                PointF[] ptsTelevision = new PointF[goodMatches.Size];
                PointF[] ptsScene = new PointF[goodMatches.Size];
                for (int i = 0; i < goodMatches.Size; i++)
                {
                    ptsTelevision[i] = keypointsTelevision[goodMatches[i].QueryIdx].Point;
                    ptsScene[i] = keypointsScene[goodMatches[i].TrainIdx].Point;
                }

                Mat homography = CvInvoke.FindHomography(ptsTelevision, ptsScene, RobustEstimationAlgorithm.Ransac, 5);
                if (homography != null)
                {
                    // Draw the detected corners on the scene image
                    Rectangle rect = new Rectangle(Point.Empty, televisionImage.Size);
                    PointF[] corners = new PointF[]
                    {
                    new PointF(rect.Left, rect.Top),
                    new PointF(rect.Right, rect.Top),
                    new PointF(rect.Right, rect.Bottom),
                    new PointF(rect.Left, rect.Bottom)
                    };
                    corners = CvInvoke.PerspectiveTransform(corners, homography);

                    for (int i = 0; i < 4; i++)
                        CvInvoke.Line(sceneImage, Point.Round(corners[i]), Point.Round(corners[(i + 1) % 4]), new MCvScalar(0, 255, 0), 2);
                }
            }

            // Show the result
            CvInvoke.Imshow("Detected Television", sceneImage);
            CvInvoke.WaitKey(0);
            CvInvoke.DestroyAllWindows();
        }
        private static void Test()
        {
            Mat roiImage = new Mat();
            Console.WriteLine("Running2");
            // Path to the input image
            Image<Bgr,byte> image = null;
            OpenFileDialog dialog = new OpenFileDialog();
            if(dialog.ShowDialog() == DialogResult.OK)
            {
                image = new Image<Bgr, byte>(dialog.FileName).Resize(640, 480, Inter.Cubic);
            }
          

            // Load the image
           
            

            // Initialize the YOLO model
            string model = "D:\\Project\\Yolo\\yolov3.weights"; // Path to the weights file
            string cfg = "D:\\Project\\Yolo\\yolov3.cfg"; // Path to the cfg file
            string classNamesFile = "D:\\Project\\Yolo\\coco.names"; // Path to the COCO class names file

            // Load the class names
            string[] classNames = System.IO.File.ReadAllLines(classNamesFile);

            // Load the network
            Net net = DnnInvoke.ReadNetFromDarknet(cfg, model);

            // Prepare the image for the model
            Mat inputBlob = DnnInvoke.BlobFromImage(image, 1 / 255.0, new Size(640, 480), swapRB: true);

            // Set the input to the network
            net.SetInput(inputBlob);
            //set prefer backend

            //  net.SetPreferableBackend(Emgu.CV.Dnn.Backend.OpenCV);

            //  net.SetPreferableTarget(Target.Cpu);

            // Perform the detection
            VectorOfMat outputs = new VectorOfMat();
            net.Forward(outputs, net.UnconnectedOutLayersNames);

            Console.WriteLine(outputs);
            // Process the results
            for (int i = 0; i < outputs.Size; i++)
            {
                Mat output = outputs[i];
                float[,] data = output.GetData(true) as float[,];
                float maxConfident = 0;
                var dataToEvaluate = 0;
                for (int j = 0; j < data.GetLength(0); j++)
                {
                    float confidence = data[j, 4];
                    if (confidence > maxConfident)
                    {
                        maxConfident = confidence;
                        dataToEvaluate = j;
                    }                
                }
               
                    // Find the class with the highest score
                    int classId = 0;
                    float maxScore = 0;
                    for (int k = 5; k < data.GetLength(1); k++)
                    {
                        if (data[dataToEvaluate, k] > maxScore)
                        {
                            maxScore = data[dataToEvaluate, k];
                            classId = k - 5;
                        }
                    }
                    // Check if the detected class is a television
                    if (classNames[classId] == "tvmonitor")
                    {
                        // Extract the bounding box
                        int centerX = (int)(data[dataToEvaluate, 0] * image.Width);
                        int centerY = (int)(data[dataToEvaluate, 1] * image.Height);
                        int width = (int)(data[dataToEvaluate, 2] * image.Width);
                        int height = (int)(data[dataToEvaluate, 3] * image.Height);
                        Rectangle rect = new Rectangle(centerX - width / 2, centerY - height / 2, width+10, height+10);

                    // Create a new image containing only the ROI
                         roiImage = new Mat(image.Mat, rect);
                    // Draw the bounding box
                    //  CvInvoke.Rectangle(image, rect, new MCvScalar(0, 255, 0), 2);
                }
                
            }
           
            // Show the image
            CvInvoke.Imshow("Detected Televisions", roiImage);
            CvInvoke.WaitKey(0);
            CvInvoke.DestroyAllWindows();
 
      
        }
       
    }
}
using Emgu.CV.CvEnum;
using Emgu.CV.Structure;
using Emgu.CV.Util;
using Emgu.CV;
using System.Runtime.InteropServices;
using System.Text.Json;
using AutoHotkey.Interop;
using AForge.Video.DirectShow;

namespace LightGun
{
    public partial class Form1 : Form
    {
        static int ixres = 640;
        static int iyres = 480;

        static int xres = 1920;
        static int yres = 1080;

        public static float sWidth = 2;

        static TransparentForm border;
        public static bool movable = false;
        public static bool outSideOfScreen = true;
        bool streamVideo = false;
        public bool init = false;
        public static string clickOutside;
        public static string holdOutside;
        //Camera variable
        static int cameraIndex = -1;
        static VideoCapture capture = new VideoCapture(cameraIndex);
        ArduinoCom arduinoCom;
        Mat frame = new Mat();
        Image<Bgr, byte> image;
        Size frameSize = new Size(ixres, iyres);

        //Mouse variable
        [DllImport("user32.dll")]
        private static extern bool SetCursorPos(int x, int y);
        private const int MOUSEEVENTF_LEFTDOWN = 0x02;
        private const int MOUSEEVENTF_LEFTUP = 0x04;

        float xOffset = 0;
        float yOffset = 0;
        //Camera Property
        int threadhold = 200;
        int brightness = 0;
        int contrast = 0;
        int hue = 0;
        int saturation = 0;
        int sharpness = 0;
        int gamma = 0;
        int whiteBalance = 0;
        int exposure = 0;


        Settings settings;

        Image<Gray, Byte> gray;
        Mat hierarchy = new Mat();
        Mat matrix = new Mat();
        Mat transformedPointMat = new Mat();

        static AutoHotkeyEngine ahk = AutoHotkeyEngine.Instance;
        public Form1()
        {
            //ahk.Suspend();
            InitializeComponent();

            //create new hotkeys

            init = true;
            this.FormBorderStyle = FormBorderStyle.FixedSingle;
            this.MaximizeBox = false;
            KeyPreview = true;
            pictureBox1.SizeMode = PictureBoxSizeMode.StretchImage;
            pictureBox2.SizeMode = PictureBoxSizeMode.StretchImage;
            string jsonFilePath = ".\\setting.json";
            string jsonString = File.ReadAllText(jsonFilePath);
            settings = JsonSerializer.Deserialize<Settings>(jsonString);
            sWidth = settings.Border;
            borderTextBox.Text = sWidth.ToString();
            LoadWebcams();
            clickOutside = settings.ClickOutSide;
            holdOutside = settings.HoldOutSide;
            clickOutComboBox.SelectedItem = clickOutside.ToString();
            holdOutComboBox.SelectedItem = holdOutside.ToString();
            string script = $@"
clickAction := ""{clickOutside}""
holdAction := ""{holdOutside}""
LButton::

    if (clickAction = ""Click Right"")
        Click right
    else if (clickAction = ""Click Middle"")
        Click middle
    else
        Send %clickAction%

    SetTimer, SendRightClick, 10
    ; Set a timer to run the SendMiddleClick label every 2000 milliseconds (2 seconds)
    SetTimer, SendMiddleClick, 1000
return

LButton Up::
    SetTimer, SendRightClick, Off 
    SetTimer, SendMiddleClick, Off
return

SendMiddleClick:
    SetTimer, SendRightClick, Off 
    if (holdAction = ""Click Right"")
        Click right
    else if (holdAction = ""Click Middle"")
        Click middle
    else
        Send %holdAction%
return
SendRightClick:

    if (clickAction = ""Click Right"")
        Click right
    else if (clickAction = ""Click Middle"")
        Click middle
    else
        Send %clickAction%

   
return

StopTimer(){{
 SetTimer, SendRightClick, Off 
 SetTimer, SendMiddleClick, Off
}}
";
            ahk.ExecRaw(script);
            ahk.Suspend();

           arduinoCom = new ArduinoCom();
            arduinoCom.OpenPort("COM12");

        }
        private void LoadWebcams()
        {
            // Create a collection to hold the video devices
            FilterInfoCollection videoDevices = new FilterInfoCollection(FilterCategory.VideoInputDevice);

            // Check if any video devices are found
            if (videoDevices.Count == 0)
            {
                MessageBox.Show("No webcams found.");
                return;
            }
            comboBox1.Sorted = false;
            // Add each video device to the ComboBox
            foreach (FilterInfo device in videoDevices)
            {
                comboBox1.Items.Add(device.Name);
            }
        }
        private void SetCamera()
        {

            // Set the capture resolution
            capture.Set(CapProp.FrameWidth, ixres);
            capture.Set(CapProp.FrameHeight, iyres);
            capture.Set(CapProp.Fps, 30);

            // Path to the JSON file

            // Read the JSON file

            // Deserialize the JSON content into the Settings class

            // Assign the values to the variables
            threadhold = settings.Threadhold;
            brightness = settings.Brightness;
            contrast = settings.Contrast;
            hue = settings.Hue;
            saturation = settings.Saturation;
            sharpness = settings.Sharpness;
            gamma = settings.Gamma;
            whiteBalance = settings.WhiteBalance;
            exposure = settings.Exposure;

            xOffset = settings.Xoffset;
            yOffset = settings.Yoffset;



            tTrackBar.Value = threadhold;
            bTrackBar.Value = brightness;
            cTrackBar.Value = contrast;
            hTrackBar.Value = hue;
            saTrackBar.Value = saturation;
            shTrackBar.Value = sharpness;
            gTrackBar.Value = gamma;
            wTrackBar.Value = whiteBalance;
            eTrackBar.Value = exposure;




            tTextBox.Text = threadhold.ToString();
            bTextBox.Text = brightness.ToString();
            cTextBox.Text = contrast.ToString();
            hTextBox.Text = hue.ToString();
            saTextBox.Text = saturation.ToString();
            shTextBox.Text = sharpness.ToString();
            gTextBox.Text = gamma.ToString();
            wTextBox.Text = whiteBalance.ToString();
            eTextBox.Text = exposure.ToString();



            capture.Set(CapProp.Brightness, brightness);
            capture.Set(CapProp.Contrast, contrast);
            capture.Set(CapProp.Hue, hue);
            capture.Set(CapProp.Saturation, saturation);
            capture.Set(CapProp.Sharpness, sharpness);
            capture.Set(CapProp.Gamma, gamma);
            capture.Set(CapProp.WhiteBalanceRedV, whiteBalance);
            capture.Set(CapProp.Exposure, exposure);

        }



        public static void MoveMouseToPointAsync(PointF targetPoint, int steps = 16, int duration = 35)
        {
            if (targetPoint == PointF.Empty) return;
            int x = (int)targetPoint.X;
            int y = (int)targetPoint.Y;
            
            if (movable)
                SetCursorPos(x, y);
                
        }

        public static void StartStop()
        {
            movable = !movable;
            button1.Text = movable ? "Stop" : "Start";
            button1.BackColor = movable ? Color.Red : Color.Green;
           if(movable)
            ahk.UnSuspend();
           else ahk.Suspend();
        }
        private void button1_Click(object sender, EventArgs e)
        {

            StartStop();
        }

        private async Task StreamVideo()
        {
            capture.Read(frame);
            SetCamera();
            while (streamVideo)
            {
                try
                {
                    capture.Read(frame);
                    CvInvoke.Resize(frame, frame, frameSize);
                    image = frame.ToImage<Bgr, byte>();
                    MoveMouseToPointAsync(DetectEdge(image));                    
                    await Task.Delay(1);
                }
                catch
                {
                   
                }


            }
        }
        VectorOfPoint BiggestContour(List<VectorOfPoint> contours)
        {
            VectorOfPoint biggest = new VectorOfPoint();
            double maxArea = 0;
            foreach (var contour in contours)
            {
                double area = CvInvoke.ContourArea(contour);
                VectorOfPoint approx = new VectorOfPoint();
                CvInvoke.ApproxPolyDP(contour, approx, 0.015 * CvInvoke.ArcLength(contour, true), true);
                if (area > maxArea && approx.Size == 4)
                {
                    biggest = approx;
                    maxArea = area;
                }
            }
            return biggest;
        }

        private PointF DetectEdge(Image<Bgr, byte> image)
        {

            if (rawCheckBox.Checked)
                pictureBox1.Image = image.ToBitmap();

            gray = image.Convert<Gray, Byte>();
            //  CvInvoke.CLAHE(gray, 2, new Size(8, 8), gray);
            //  CvInvoke.GaussianBlur(gray, gray, new Size(5, 5), 0);
            CvInvoke.Threshold(gray, gray, threadhold, 255, ThresholdType.Binary);
            VectorOfVectorOfPoint contours = new VectorOfVectorOfPoint();
            CvInvoke.FindContours(gray, contours, hierarchy, RetrType.Tree, ChainApproxMethod.ChainApproxSimple);
            List<VectorOfPoint> contourList = new List<VectorOfPoint>();
            for (int i = 0; i < contours.Size; i++)
            {
                if (contours[i].Size >= 4)
                {
                    contourList.Add(contours[i]);
                }

            }


            VectorOfPoint biggest = BiggestContour(contourList);
            PointF topLeft = PointF.Empty;
            PointF topRight = PointF.Empty;
            PointF bottomRight = PointF.Empty;
            PointF bottomLeft = PointF.Empty;

            if (biggest.Size == 4)
            {
                double area = CvInvoke.ContourArea(biggest);
                if (area < 28800)
                {
                    if (processCheckBox.Checked)
                    {
                        var process = gray.ToBitmap();
                        pictureBox2.Image = process;
                    }
                    outSideOfScreen = true;
                    if(movable)
                        ahk.UnSuspend();
                    else
                        ahk.Suspend();
                    return System.Drawing.PointF.Empty;
                }
                // Convert VectorOfPoint to PointF array
                Point[] points = biggest.ToArray();
                PointF[] corners = Array.ConvertAll(points, p => new PointF(p.X, p.Y));

                // Calculate the center of the contour
                float centerX = 0, centerY = 0;
                foreach (var corner in corners)
                {
                    centerX += corner.X;
                    centerY += corner.Y;
                }
                centerX /= corners.Length;
                centerY /= corners.Length;

                // Assign corners based on their position relative to the center
                foreach (var corner in corners)
                {
                    if (corner.X < centerX && corner.Y < centerY) topLeft = corner;
                    else if (corner.X > centerX && corner.Y < centerY) topRight = corner;
                    else if (corner.X > centerX && corner.Y > centerY) bottomRight = corner;
                    else if (corner.X < centerX && corner.Y > centerY) bottomLeft = corner;
                }


                PointF pointToTrack = new PointF(ixres / 2 + xOffset, iyres / 2 + yOffset);
                Mat pointMat = new Mat(1, 1, DepthType.Cv32F, 2);
                pointMat.SetTo(new float[] { pointToTrack.X, pointToTrack.Y });
                PointF[] pts1 = new PointF[] {
                            topLeft,    // corners[0]
                            topRight,   // corners[1]
                            bottomRight,// corners[2]
                            bottomLeft  // corners[3]
                    };
                PointF destTopLeft = new PointF(0, 0);
                PointF destTopRight = new PointF(ixres, 0);
                PointF destBottomRight = new PointF(ixres, iyres);
                PointF destBottomLeft = new PointF(0, iyres);
                PointF[] pts2 = new PointF[] {
                            destTopLeft,    // Destination for topLeft
                            destTopRight,   // Destination for topRight
                            destBottomRight,// Destination for bottomRight
                            destBottomLeft  // Destination for bottomLeft
                    };

                if (processCheckBox.Checked)
                {
                    var process = gray.ToBitmap().ToImage<Bgr, byte>();
                    process.Draw(new CircleF(topLeft, 20), new Bgr(0, 0, 255), 10);
                    process.Draw(new CircleF(topRight, 20), new Bgr(0, 255, 0), 10);
                    process.Draw(new CircleF(bottomRight, 20), new Bgr(255, 0, 0), 10);
                    process.Draw(new CircleF(bottomLeft, 20), new Bgr(0, 255, 255), 10);
                    process.Draw(new CircleF(new PointF(pointToTrack.X, pointToTrack.Y), 10), new Bgr(255, 255, 0), 5);
                    pictureBox2.Image = process.ToBitmap();
                }

                // Convert PointF arrays to Mat
                using (Mat srcPoints = new Mat(4, 1, DepthType.Cv32F, 2))
                using (Mat dstPoints = new Mat(4, 1, DepthType.Cv32F, 2))
                {
                    for (int i = 0; i < 4; i++)
                    {
                        srcPoints.SetTo(pts1);
                        dstPoints.SetTo(pts2);
                    }
                    // Get the perspective transformation matrix
                    matrix = CvInvoke.GetPerspectiveTransform(srcPoints, dstPoints);
                    // Apply the perspective transformation

                    CvInvoke.PerspectiveTransform(pointMat, transformedPointMat, matrix);
                    // Convert the transformed Mat back to PointF
                    float[] transformedPointValues = new float[2];
                    Marshal.Copy(transformedPointMat.DataPointer, transformedPointValues, 0, 2);
                    PointF transformedPoint = new PointF((transformedPointValues[0] / ixres) * xres, (transformedPointValues[1] / iyres) * yres);
                    arduinoCom.SendCursorPos((int)transformedPointValues[0], (int)transformedPointValues[1]);

                    bool outsideX = transformedPoint.X < 0 || transformedPoint.X > xres;
                    bool outsideY = transformedPoint.Y < 0 || transformedPoint.Y > yres;
                    if ( outsideX||outsideY)
                    {
                       
                        outSideOfScreen = true;
                        if (movable)
                            ahk.UnSuspend();
                        else
                            ahk.Suspend();
                    }
                    else
                    {
                        outSideOfScreen = false;
                      
                        ahk.ExecFunction("StopTimer");
                        ahk.Suspend();
                    }


                    return transformedPoint;
                }

            }
            else
            {
                if (processCheckBox.Checked)
                {
                    var process = gray.ToBitmap();
                    pictureBox2.Image = process;
                }
     
                outSideOfScreen = true;
                if (movable)
                    ahk.UnSuspend();
                else
                    ahk.Suspend();
            }
           
            outSideOfScreen = true;
            if (movable)
                ahk.UnSuspend();
            else
                ahk.Suspend();
            return PointF.Empty;




        }

        private void button11_Click(object sender, EventArgs e)
        {
            // Path to the JSON file
            string jsonFilePath = ".\\setting.json";
            // Serialize the object back to a JSON string
            string updatedJsonString = JsonSerializer.Serialize(settings, new JsonSerializerOptions { WriteIndented = true });

            // Write the JSON string to a file
            File.WriteAllText(jsonFilePath, updatedJsonString);
        }

        private void up10Button_Click(object sender, EventArgs e)
        {
            yOffset -= 10;
            settings.Yoffset = (int)yOffset;
        }

        private void down10Button_Click(object sender, EventArgs e)
        {
            yOffset += 10;
            settings.Yoffset = (int)yOffset;
        }

        private void left10Button_Click(object sender, EventArgs e)
        {
            xOffset -= 10;
            settings.Xoffset = (int)xOffset;
        }

        private void right10Button_Click(object sender, EventArgs e)
        {
            xOffset += 10;
            settings.Xoffset = (int)xOffset;
        }

        private void up1Button_Click(object sender, EventArgs e)
        {
            yOffset -= 1;
            settings.Yoffset = (int)yOffset;
        }

        private void down1Button_Click(object sender, EventArgs e)
        {
            yOffset += 1;
            settings.Yoffset = (int)yOffset;
        }

        private void left1Button_Click(object sender, EventArgs e)
        {
            xOffset -= 1;
            settings.Xoffset = (int)xOffset;
        }

        private void right1Button_Click(object sender, EventArgs e)
        {
            xOffset += 1;
            settings.Xoffset = (int)xOffset;
        }





        public static void OpenBorder()
        {
            int screenWidth = Screen.PrimaryScreen.Bounds.Width;
            int screenHeight = Screen.PrimaryScreen.Bounds.Height;

            if (border != null && border.Visible)
            {
                border.Dispose();
                border = null;
                xres = screenWidth;
                yres = screenHeight;
            }
            else
            {
                border = new TransparentForm(sWidth, screenWidth, screenHeight);
                border.Show();
                xres = screenWidth;
                yres = screenHeight;
            }

        }

        private void button2_Click(object sender, EventArgs e)
        {
            comboBox1.Items.Clear();
            LoadWebcams();
        }


    }
}
